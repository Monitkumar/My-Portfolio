# [Project 1 : Disastrous Tweets Classification üê¶](https://share.streamlit.io/monitkumar/tweets_classification_app/main/APP_TWEETS.py)
### Objective : Build the classification model to predict from the tweet which is real disaster and which is not
One of our clients is a disaster relief organization. So, they actually rely upon twitter as an important medium for their communication. But they often get misled with the kind of tweets whether that actually implies the disaster or not.

# Steps:
1. Identify and collect Twitter data.
2. Label the data.
3. Do feature engineering.
4. Transform the data.
5. Train the model.
6. Evaluate the model.

![wordcloud](https://user-images.githubusercontent.com/39349107/167862108-21d810aa-84ed-4945-85f2-3a28c734a843.png)

![](/Images/upload2.png)

Used ComplementNB as the final algorithm for model building and created a webapp using streamlit and deployed on streamlit cloud as well.

# [Project 2 : Churn Rate Prediction](https://github.com/Monitkumar/Churn-Rate-Prediction-Project)

### Objective : To predict whether a customer is going to cancel the booking or not.

Made predictions by what factor the hotel booking is being cancelled by customer and reason behind it.
![image](https://user-images.githubusercontent.com/39349107/167861659-ec4ec61e-d299-45fc-910d-3676e4280311.png)


Used xgboost as the algorithm for our problem with highest(0.84) accuracy and use it as our final model.
Then deployed the webapp using streamlit on local server.
